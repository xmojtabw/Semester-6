\chapter{تشخیص فیشینگ\footnote{Phishing} توسط شبکه‌های کانولوشنی\footnote{CNN: Convulotional Neural Networks}}


\section{مقدمه}

فیشینگ به عنوان یک حمله سایبری\footnote{Cyber Attack} شناخته می‌شود که در آن مهاجمان سعی می‌کنند کاربران را فریب دهند تا اطلاعات حیاتی و شخصی نظیر جزئیات کارت اعتباری و رمزهای عبور را فاش کنند. این نوع حملات معمولاً از طریق ایمیل‌ها، پیام‌های فوری یا تماس‌های تلفنی آغاز می‌شوند. یکی از روش‌های رایج فیشرها\footnote{phishers} طراحی وب‌سایت‌های فریبنده است که تقلیدی از وب‌سایت‌های قانونی (مانند PayPal یا (eBay بوده و بر روی دامنه‌های هک شده میزبانی می‌شوند. تشخیص تفاوت بین صفحات وب قانونی و تقلیدی برای چشم انسان دشوار است. با دسترسی کاربر به سایت شبیه‌سازی شده، اطلاعات حیاتی با استفاده از اسکریپت‌ها\footnote{scripts} به سرقت می‌رود. جرایم فیشینگ هر ساله به دلیل رشد سریع کاربران تجارت الکترونیک در حال افزایش است.

	طبق گزارش گروه کاری ضد فیشینگ ،(APWG) تعداد کل سایت‌های فیشینگ شناسایی شده در سه‌ماهه اول سال ۲۰۱۹ به ۱۸۰{٬}۷۶۸ مورد رسید که افزایش قابل توجهی نسبت به سه‌ماهه چهارم ۲۰۱۸ (۱۳۸{٬}۳۲۸ مورد) و سه‌ماهه سوم ۲۰۱۸ (۱۵۱{٬}۰۱۴ مورد) نشان می‌دهد. فیشینگ به دلیل خسارات گسترده به صنایع هدف مانند پرداخت و مؤسسات مالی، به یک مشکل جدی تبدیل شده است.

روش‌های سنتی تشخیص فیشینگ، مانند استفاده از لیست‌های سیاه\footnote{Black Lists}، در برابر حملات روز صفر\footnote{Zero Days} که URL های\footnote{Uniform Resource Locator} فیشینگ جدید هنوز در لیست سیاه ثبت نشده‌اند، کارایی ندارند. بسیاری از تکنیک‌های تشخیص مبتنی بر اکتشافی، ویژگی‌ها را از محتوای صفحات وب و خدمات شخص ثالث استخراج می‌کنند. با این حال، استفاده از خدمات شخص ثالث مانند رتبه صفحه یا معیارهای ترافیک شبکه، می‌تواند زمان‌بر باشد و منجر به کندی فرآیند طبقه‌بندی شود. تکنیک‌های یادگیری ماشین نیز برای بررسی URL صفحات وب با مجموعه‌های ویژگی دست‌ساز استفاده شده‌اند. با این حال، این روش‌ها به مهندسی ویژگی دستی نیاز دارند و در شناسایی حملات فیشینگ نوظهور کارآمد نیستند.

با پیشرفت‌های اخیر در تکنیک‌های یادگیری عمیق\footnote{Deep Learning}، بسیاری از مدل‌های مبتنی بر یادگیری عمیق نیز برای بهبود عملکرد طبقه‌بندی معرفی شده‌اند. یادگیری عمیق می‌تواند ویژگی‌ها را به صورت خودکار از داده‌های خام استخراج کند و نیازی به دانش قبلی متخصصان امنیت سایبری ندارد. در این مقاله، ما یک مدل مبتنی بر یادگیری عمیق را برای تشخیص URL فیشینگ پیشنهاد می‌کنیم. به طور خاص، ما از شبکه‌های عصبی کانولوشنی در سطح کاراکتر استفاده می‌کنیم. این رویکرد به‌ویژه برای URL ها مفید است، زیرا آن‌ها اغلب حاوی کلمات بی‌معنی هستند و مهاجمان می‌توانند با تغییرات کوچک کاراکتری (مانند ``www.icbc.com'' به ``www.lcbc.com'')، URL های فیشینگ را شبیه به URL های قانونی کنند.

مزایای اصلی مدل پیشنهادی ما عبارتند از:
\begin{itemize}
	\item \textbf{عدم وابستگی به سرویس‌های شخص ثالث:}
	 مدل ما فقط از URL وب‌سایت استفاده می‌کند و نیازی به لیست‌های سیاه یا  سفید\footnote{White Lists}، رتبه صفحه یا معیارهای ترافیک شبکه ندارد. زمان تشخیص برای طبقه‌بندی هر URL تنها ۰٫۴۷ میلی‌ثانیه است.
	\item \textbf{استقلال از زبان:} از آنجا که ویژگی‌ها از رشته URL استخراج و بر اساس یک واژگان کاراکتری از پیش تعریف‌شده جاسازی می‌شوند، مدل ما برای وب‌سایت‌ها با محتوای هر زبانی مؤثر است.
	\item \textbf{قابلیت تشخیص وب‌سایت‌های جدید (حملات روز صفر):} به دلیل استفاده از ویژگی‌های جاسازی در سطح کاراکتر، مدل ما می‌تواند به راحتی برای URL های جدید تعمیم یابد و سایت‌های فیشینگ جدید را شناسایی کند که قبلاً به عنوان فیشینگ طبقه‌بندی نشده‌اند.
	\item \textbf{عدم نیاز به کارشناسان امنیت سایبری:} CNN به طور خودکار ویژگی‌ها را برای نمایش URL تشخیص می‌دهد و نیازی به مهندسی ویژگی‌های پیچیده و دستی توسط کارشناسان در طول فرآیند یادگیری ندارد.
\end{itemize}

\section{کارهای مرتبط}

به طور کلی، تشخیص فیشینگ می‌تواند از طریق روش‌های مبتنی بر لیست، یادگیری ماشین، اکتشافی یا یادگیری عمیق انجام شود. با این حال، مشکل فیشینگ آن‌قدر پیچیده است که هیچ راه‌حل قاطعی برای مقابله مؤثر با همه تهدیدات وجود ندارد؛ بنابراین، اغلب چندین تکنیک برای جلوگیری از حملات خاص به کار گرفته می‌شوند. روش‌های حفاظتی به دو گروه اصلی تقسیم می‌شوند: افزایش دانش کاربر و استفاده از نرم‌افزارهای اضافی (شکل ۱−۳ را ببینید).
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{screenshot003}
	\caption{مروری بر تکنیک‌های تشخیص فیشینگ}
	\label{fig:screenshot003}
\end{figure}

\subsection{تشخیص مبتنی بر لیست}
تکنیک‌های تشخیص فیشینگ مبتنی بر لیست به دو دسته لیست سفید و لیست سیاه تقسیم می‌شوند. لیست سفید شامل URL ها و آدرس‌های IP قانونی است که برای اعتبارسنجی یک URL مشکوک استفاده می‌شود. تکنیک‌های مبتنی بر لیست سیاه به طور گسترده‌ای در نوار ابزارهای ضد فیشینگ در دسترس عموم مانند Browsing Safe Google استفاده می‌شوند. اگرچه این روش‌ها می‌توانند دقت نسبتاً بالایی داشته باشند، اما نگهداری یک لیست جامع از URL های فیشینگ دشوار است، زیرا URL های جدید هر روز ایجاد می‌شوند. نقطه ضعف اصلی این روش‌ها این است که نمی‌توانند حملات روز صفر را شناسایی کنند.

\subsection{تشخیص مبتنی بر اکتشافی}
اساس تکنیک‌های تشخیص مبتنی بر اکتشافی، ایجاد ویژگی‌های سایت فیشینگ بر اساس بسیاری از ویژگی‌های دست‌ساز، مانند ویژگی‌های مبتنی بر URL، محتوای صفحه وب و شباهت‌های بصری وب‌سایت است. این روش‌ها مانند \lr{Cantina} و \lr{Cantina+} از موتورهای جستجو و قوانین اکتشافی برای تشخیص استفاده می‌کنند. با این حال، برخی از این روش‌ها به زبان انگلیسی محدود بوده یا به دلیل وابستگی به موتورهای جستجو و سرویس‌های شخص ثالث، زمان‌بر هستند.

\subsection{تشخیص مبتنی بر یادگیری ماشین}
برای مقابله با محدودیت‌های زمانی و محاسباتی در جمع‌آوری ویژگی‌ها، در سال‌های اخیر از تکنیک‌های یادگیری ماشین (مانند \lr{K-nearest Neighbor}، \lr{XGBoost}، \lr{Naïve Bayes}، رگرسیون خطی، \lr{SVM} و جنگل تصادفی\footnote{Random Forest}) برای تشخیص فیشینگ استفاده شده است. این روش‌ها ویژگی‌ها را از URL ها استخراج کرده و سپس طبقه‌بندی می‌کنند. با این حال، این روش‌ها نمی‌توانند با اطلاعات جدیدی که در مجموعه آموزشی وجود ندارند، مقابله کنند.

\subsection{تشخیص مبتنی بر یادگیری عمیق}
به دلیل موفقیت یادگیری عمیق در پردازش زبان طبیعی، برخی از این تکنیک‌ها (مانند \lr{CNN}، \lr{RNN}، \lr{RCNN} و \lr{DNN}) اخیراً برای تشخیص فیشینگ به کار گرفته شده‌اند. اگرچه تکنیک‌های یادگیری عمیق به دلیل زمان آموزش گسترده کمتر مورد استفاده قرار گرفته‌اند، اما اغلب دقت بیشتری را ارائه می‌دهند و ویژگی‌ها را به طور خودکار از داده‌های خام استخراج می‌کنند. به عنوان مثال، مدل \lr{PDRCNN} از ترکیب \lr{LSTM} و \lr{CNN} برای استخراج ویژگی‌های جهانی و محلی URL استفاده می‌کند. برخی دیگر از مدل‌ها نیز ویژگی‌های چندبعدی را از URL ها استخراج می‌کنند.

\subsection{روش‌های ترکیبی}
تکنیک‌های تشخیص ترکیبی به ترکیب بیش از یکی از تکنیک‌های قبلی برای دستیابی به عملکرد بهتر در تشخیص سایت‌های فیشینگ متکی هستند. به عنوان مثال، \lr{Yang} و همکاران از الگوریتم‌های یادگیری عمیق (\lr{CNN-LSTM}) برای استخراج ویژگی‌های URL و سپس ترکیب آن‌ها با ویژگی‌های آماری ،URL کد صفحه وب و متن صفحه وب برای طبقه‌بندی با الگوریتم یادگیری ماشین (\lr{XGBoost}) استفاده می‌کنند.

\section{روش‌شناسی پیشنهادی}

مهاجمان معمولاً URL های فیشینگ را به گونه‌ای ایجاد می‌کنند که شبیه وب‌سایت‌های قانونی به نظر برسند. ایده اصلی این مقاله، تشخیص سریع وب‌سایت‌های فیشینگ با استفاده از ویژگی‌های سبک وزن است. این امر با استخراج ویژگی‌ها تنها از URL و بدون بازدید از محتوای وب‌سایت حاصل می‌شود.


\subsection{مؤلفه‌های URL}
URL شامل مؤلفه‌هایی نظیر پروتکل (مثل \lr{http, https})، آدرس IP یا دامنه میزبان، مسیر منبع، و ترکیب نام دامنه سطح دوم و سطح بالا است که به آن \lr{domain host} گفته می‌شود. شکل URL در فرآیند تشخیص نقش کلیدی دارد.

\subsection{طراحی مدل}
مدل پیشنهادی بر پایه‌ی شبکه عصبی کانولوشنی در سطح کاراکتر است که هدف آن یادگیری ساختار ترتیبی URL ها است.

\subsubsection{ویژگی‌های جاسازی کاراکتر}
جاسازی در سطح کاراکتر از یک واژگان ۹۵ کاراکتری (شامل حروف بزرگ و کوچک، ارقام و علائم خاص) بهره می‌گیرد. هر کاراکتر توسط رمزگذاری یک‌داغ\footnote{Hot-one} به بردار \lr{-m}بعدی نگاشت می‌شود. برای تطابق با معماری ،CNN طول همه‌ی URL ها به ۲۰۰ کاراکتر استانداردسازی شده است \lr{.(padding)}

\subsubsection{ساختار CNN}
ساختار CNN شامل:
\begin{itemize}
	\item یک لایه جاسازی برای کاهش ابعاد ماتریس sparse
	\item هفت لایه کانولوشنی با تابع فعال‌سازی \lr{ReLU} برای استخراج ویژگی
	\item سه لایه کاملاً متصل جهت تحلیل ویژگی‌های عمیق
	\item یک لایه خروجی با دو گره\footnote{Node} و تابع softmax برای تعیین برچسب نهایی URL به عنوان فیشینگ یا معتبر
\end{itemize}

\subsection{ویژگی‌های URL}
چهار گروه ویژگی مورد استفاده قرار گرفت:
\begin{enumerate}
	\item ویژگی‌های سطح کاراکتر با جاسازی
	\item ویژگی‌های \lr{TF-IDF} سطح کاراکتر
	\item ویژگی‌های دست‌ساز مبتنی بر اجزای URL
	\item ویژگی‌های شمارشگر سطح کاراکتر \lr{(count vector)}
\end{enumerate}

\subsection{الگوریتم‌های طبقه‌بندی}
برای مقایسه عملکرد، از الگوریتم‌هایی نظیر
 \lr{،Naïve Bayes Logistic ،Regression ،Random Forest ،DNN CNN ،XGBoost} 
 استفاده شد. معیار اصلی، دقت تشخیص فیشینگ بود.

\section{آزمایش و تحلیل نتایج}

\subsection{مجموعه داده}
چهار مجموعه داده مورد استفاده قرار گرفت:
\begin{itemize}
	\item \lr{D1}: شامل 318{,}642 URL جمع‌آوری شده؛
	\item \lr{D2}، \lr{D3}، \lr{D4}: مجموعه‌های داده مرجع استخراج‌شده از پژوهش‌های پیشین مانند OpenPhish و .PhishTank
\end{itemize}

\subsection{ارزیابی عملکرد بر روی \lr{D1}}
تمام گروه‌های ویژگی \lr{(\lr{FG1}~FG4)} روی \lr{D1} با طبقه‌بندهای مختلف تست شدند. بهترین نتیجه مربوط به CNN با \lr{FG2} بود (دقت: \lr{ F1: 95.13\% }).

\subsection{ارزیابی بر روی \lr{D3}}
\lr{FG1} و \lr{FG2} به ترتیب با طبقه‌بندهای کلاسیک و مدل‌های عمیق ارزیابی شدند. CNN با FG2 بهترین عملکرد را داشت (دقت: \lr{95.41\%}).

\subsection{ارزیابی بر روی \lr{D2}}
مدل CNN با \lr{FG2} دقت \lr{98.58\%} را بدست آورد که بالاتر از سایر مدل‌های یادگیری عمیق مانند RNN و VDCNN بود.

\subsection{مقایسه با روش‌های موجود}
مدل پیشنهادی در مقایسه با روش‌های ،Sahingoz Rao و Le عملکرد بهتری داشت و روی \lr{D2} به دقت \lr{98.58\%} رسید.

\section{نتیجه‌گیری}

مدل مبتنی بر CNN با ورودی در سطح کاراکتر، توانست بدون نیاز به ویژگی‌های مهندسی‌شده و صرفاً از طریق تحلیل ساختار URL، عملکرد مناسبی در تشخیص فیشینگ داشته باشد. مزیت این روش، استقلال از دسترسی به وب و مناسب بودن برای پیاده‌سازی سمت کلاینت است. با این حال، زمان آموزش بالا و ضعف در تشخیص URL های کوتاه یا دارای واژگان معمول از جمله نقاط ضعف آن است.

در آینده، هدف توسعه مدل برای بهره‌گیری از محتوای HTML و کدهای سمت کاربر به منظور تقویت دقت تشخیص خواهد بود.
