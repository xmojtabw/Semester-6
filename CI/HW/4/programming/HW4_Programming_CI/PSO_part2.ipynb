{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "nUm2AYjCyMih",
      "metadata": {
        "id": "nUm2AYjCyMih"
      },
      "source": [
        "## import package and libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "kEMEZ8BCyU0F",
      "metadata": {
        "id": "kEMEZ8BCyU0F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "52d4dd30",
      "metadata": {
        "id": "52d4dd30"
      },
      "outputs": [],
      "source": [
        "# set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "# it still is somewhat random due to the nature of neural networks and CUDA operations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N5QYjeG-yWfR",
      "metadata": {
        "id": "N5QYjeG-yWfR"
      },
      "source": [
        "## Load MNIST and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9c46ae4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c46ae4f",
        "outputId": "20724ed4-1906-44ac-d2d2-7c143626a64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train_full, y_train_full), _ = tf.keras.datasets.mnist.load_data()\n",
        "X = X_train_full.reshape(-1, 28*28) / 255.0\n",
        "y = to_categorical(y_train_full)\n",
        "\n",
        "# Use only 3000 samples for speed\n",
        "X_small, y_small = X[:3000], y[:3000]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_small, y_small, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2LbUFNWhz_Zs",
      "metadata": {
        "id": "2LbUFNWhz_Zs"
      },
      "outputs": [],
      "source": [
        "def decode_particle(p):\n",
        "    neurons = [int(p[0]), int(p[1]), int(p[2])]\n",
        "    activation = ['relu', 'tanh', 'sigmoid'][int(p[3])]\n",
        "    dropout = float(p[4])\n",
        "    return neurons, activation, dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M71LlkYXz5Ul",
      "metadata": {
        "id": "M71LlkYXz5Ul"
      },
      "source": [
        "## Define the fitness function for PSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3a94d2da",
      "metadata": {
        "id": "3a94d2da"
      },
      "outputs": [],
      "source": [
        "def fitness(particle):\n",
        "    neurons, activation, dropout = decode_particle(particle)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons[0], activation=activation, input_shape=(784,)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(neurons[1], activation=activation))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(neurons[2], activation=activation))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=3, batch_size=32,\n",
        "                        verbose=0, validation_data=(X_val, y_val))\n",
        "\n",
        "    val_acc = history.history['val_accuracy'][-1]\n",
        "    return -val_acc  # because we want to maximize accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xFrvApB50HCl",
      "metadata": {
        "id": "xFrvApB50HCl"
      },
      "source": [
        "## Set PSO hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8bb6d86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8bb6d86",
        "outputId": "f6db5948-67ae-430b-e8db-0394a4e383a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "n_particles = 10\n",
        "n_iterations = 10\n",
        "w, c1, c2 = 0.5, 1.5, 1.5 # i kept these values as they are common in PSO \n",
        "\n",
        "bounds = np.array([\n",
        "    [32, 256],     # neurons layer 1\n",
        "    [32, 256],     # neurons layer 2\n",
        "    [16, 128],     # neurons layer 3\n",
        "    [0, 2.9999],   # activation function (0=relu,1=tanh,2=sigmoid)\n",
        "    [0.0, 0.5]     # dropout\n",
        "])\n",
        "\n",
        "dim = bounds.shape[0]\n",
        "positions = np.random.uniform(\n",
        "    bounds[:, 0], bounds[:, 1], size=(n_particles, dim))\n",
        "velocities = np.zeros_like(positions)\n",
        "\n",
        "pbest = positions.copy()\n",
        "pbest_fitness = np.array([fitness(p) for p in pbest])\n",
        "\n",
        "gbest_index = np.argmin(pbest_fitness)\n",
        "gbest = pbest[gbest_index].copy()\n",
        "gbest_fitness = pbest_fitness[gbest_index]\n",
        "\n",
        "history = [gbest_fitness]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ymRuV-EZ4UG4",
      "metadata": {
        "id": "ymRuV-EZ4UG4"
      },
      "source": [
        "## PSO main loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4b3787b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b3787b1",
        "outputId": "8a373c3e-9919-4304-9dde-239e57bf4ce5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1/10 - Best Accuracy: 0.9150\n",
            "Iteration 2/10 - Best Accuracy: 0.9150\n",
            "Iteration 3/10 - Best Accuracy: 0.9367\n",
            "Iteration 4/10 - Best Accuracy: 0.9367\n",
            "Iteration 5/10 - Best Accuracy: 0.9367\n",
            "Iteration 6/10 - Best Accuracy: 0.9383\n",
            "Iteration 7/10 - Best Accuracy: 0.9383\n",
            "Iteration 8/10 - Best Accuracy: 0.9383\n",
            "Iteration 9/10 - Best Accuracy: 0.9383\n",
            "Iteration 10/10 - Best Accuracy: 0.9383\n"
          ]
        }
      ],
      "source": [
        "for t in range(n_iterations):\n",
        "    for i in range(n_particles):\n",
        "        r1 = np.random.rand(dim)\n",
        "        r2 = np.random.rand(dim)\n",
        "\n",
        "        velocities[i] = (w * velocities[i] +\n",
        "                         c1 * r1 * (pbest[i] - positions[i]) +\n",
        "                         c2 * r2 * (gbest - positions[i]))\n",
        "\n",
        "        positions[i] += velocities[i]\n",
        "\n",
        "        # Clip to bounds\n",
        "        positions[i] = np.clip(positions[i], bounds[:, 0], bounds[:, 1])\n",
        "\n",
        "        fit = fitness(positions[i])\n",
        "\n",
        "        if fit < pbest_fitness[i]:\n",
        "            pbest[i] = positions[i].copy()\n",
        "            pbest_fitness[i] = fit\n",
        "\n",
        "            if fit < gbest_fitness:\n",
        "                gbest = pbest[i].copy()\n",
        "                gbest_fitness = fit\n",
        "\n",
        "    history.append(gbest_fitness)\n",
        "    print(\n",
        "        f\"Iteration {t+1}/{n_iterations} - Best Accuracy: {-gbest_fitness:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jhyoN3bc1WWS",
      "metadata": {
        "id": "jhyoN3bc1WWS"
      },
      "source": [
        "## Show best result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "j4s_a_CZ1Xo7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4s_a_CZ1Xo7",
        "outputId": "e37af756-c74d-40f2-ac67-792b351e9851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Architecture Found:\n",
            "Neurons per layer: [256, 248, 86]\n",
            "Activation: relu\n",
            "Dropout: 0.0\n",
            "Validation Accuracy: 0.9383333325386047\n"
          ]
        }
      ],
      "source": [
        "neurons, activation, dropout = decode_particle(gbest)\n",
        "print(\"Best Architecture Found:\")\n",
        "print(\"Neurons per layer:\", neurons)\n",
        "print(\"Activation:\", activation)\n",
        "print(\"Dropout:\", dropout)\n",
        "print(\"Validation Accuracy:\", -gbest_fitness)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "readyenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
