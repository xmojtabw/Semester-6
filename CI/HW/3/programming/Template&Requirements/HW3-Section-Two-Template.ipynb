{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uCObRVzMrMPj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8A2-0UyrSQc",
        "outputId": "fa02b19f-eb3d-4f13-b1bf-094abfe3e392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUBNQA123A_Q"
      },
      "source": [
        "## Section 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AfsCWDHY4Kag"
      },
      "outputs": [],
      "source": [
        "# Define the first 10 classes\n",
        "classes = [\n",
        "    'BaseballPitch',\n",
        "    'Basketball',\n",
        "    'BenchPress',\n",
        "    'Biking',\n",
        "    'Billiards',\n",
        "    'BreastStroke',\n",
        "    'CleanAndJerk',\n",
        "    'Diving',\n",
        "    'Drumming',\n",
        "    'Fencing'\n",
        "]\n",
        "\n",
        "# Define the root directory where extracted frames are stored\n",
        "frames_root_dir = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if6Y64a_08aB"
      },
      "source": [
        "### Section 1-1: Split Data paths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qcjH3UIA07i7"
      },
      "outputs": [],
      "source": [
        "def manual_split_dataset(frames_root_dir, classes, num_frames=20, train_ratio=0.8, max_videos_per_class=5):\n",
        "    \"\"\"\n",
        "    Manually splits the dataset into training and testing sets.\n",
        "\n",
        "    Args:\n",
        "        frames_root_dir (str): Path to the root directory containing class subdirectories with frame folders.\n",
        "        classes (list): List of class names to process.\n",
        "        num_frames (int, optional): Number of frames per video. Defaults to 20.\n",
        "        train_ratio (float, optional): Proportion of data to be used for training. Defaults to 0.8.\n",
        "        max_videos_per_class (int, optional): Maximum number of videos per class. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        train_frame_paths (list of list of str): Frame paths for training videos.\n",
        "        train_labels (list of int): Labels for training videos.\n",
        "        test_frame_paths (list of list of str): Frame paths for testing videos.\n",
        "        test_labels (list of int): Labels for testing videos.\n",
        "    \"\"\"\n",
        "    train_frame_paths = []\n",
        "    train_labels = []\n",
        "    test_frame_paths = []\n",
        "    test_labels = []\n",
        "\n",
        "    for class_idx, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(frames_root_dir, class_name)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            print(f\"Class directory does not exist: {class_dir}\")\n",
        "            continue\n",
        "\n",
        "        video_folders = sorted([\n",
        "            d for d in os.listdir(class_dir)\n",
        "            if os.path.isdir(os.path.join(class_dir, d))\n",
        "        ])\n",
        "\n",
        "        # Limit to the first `max_videos_per_class` videos\n",
        "        selected_video_folders = video_folders[:max_videos_per_class]\n",
        "\n",
        "        num_train = int(train_ratio * len(selected_video_folders))\n",
        "        for i, video_folder in enumerate(selected_video_folders):\n",
        "            video_dir = os.path.join(class_dir, video_folder)\n",
        "            frame_files = sorted([\n",
        "                f for f in os.listdir(video_dir)\n",
        "                if f.endswith('.jpg') or f.endswith('.png')  # Extend as needed\n",
        "            ])\n",
        "\n",
        "            # Ensure exactly `num_frames` frames are present\n",
        "            if len(frame_files) < num_frames:\n",
        "                print(f\"Not enough frames in {video_dir}. Expected {num_frames}, got {len(frame_files)}.\")\n",
        "                continue\n",
        "\n",
        "            # Get full paths for the first `num_frames` frames\n",
        "            selected_frame_files = frame_files[:num_frames]\n",
        "            selected_frame_paths = [\n",
        "                os.path.join(video_dir, f) for f in selected_frame_files\n",
        "            ]\n",
        "\n",
        "            if i < num_train:\n",
        "                #### Your Code Here!\n",
        "                # train_frame_paths\n",
        "                # train_labels\n",
        "            else:\n",
        "                #### Your Code Here!\n",
        "                # test_frame_paths\n",
        "                # test_labels\n",
        "\n",
        "    return train_frame_paths, train_labels, test_frame_paths, test_labels\n",
        "\n",
        "# Perform manual data splitting\n",
        "train_frame_paths, train_labels, test_frame_paths, test_labels = manual_split_dataset(\n",
        "    frames_root_dir=frames_root_dir,\n",
        "    classes=classes,\n",
        "    num_frames=20,\n",
        "    train_ratio=0.8,\n",
        "    max_videos_per_class=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhhAhz3u1dwJ"
      },
      "source": [
        "### Section 1-2: Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "04hBQhNq1gmC"
      },
      "outputs": [],
      "source": [
        "transform = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDctUVC01s7C"
      },
      "source": [
        "### Section 1-3:Create Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mZN6xfvq1vWU"
      },
      "outputs": [],
      "source": [
        "class CustomFrameDataset(Dataset):\n",
        "    def __init__(self, frame_paths, labels, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            frame_paths (list of list of str): List where each element is a list of frame paths for a video.\n",
        "            labels (list of int): List of labels corresponding to each video.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample. Defaults to None.\n",
        "        \"\"\"\n",
        "        self.frame_paths = frame_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_paths = self.frame_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        frames = []\n",
        "        for frame_path in frame_paths:\n",
        "            try:\n",
        "                with Image.open(frame_path) as img:\n",
        "                    img = img.convert('RGB')  # Ensure 3-channel RGB\n",
        "                    ###\n",
        "                    # Your Code Here!\n",
        "                    ###\n",
        "                    frames.append(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading frame {frame_path}: {e}\")\n",
        "\n",
        "        # Stack frames into a tensor of shape (num_frames, C, H, W)\n",
        "        frames_tensor = None\n",
        "\n",
        "        return frames_tensor, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DMGD7r51yIh"
      },
      "source": [
        "### Section 1-4: Create Dataset Instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_5imkwyCrjUb"
      },
      "outputs": [],
      "source": [
        "# Create Dataset objects\n",
        "train_dataset = None\n",
        "\n",
        "test_dataset = None\n",
        "\n",
        "# Check if datasets are not empty\n",
        "if len(train_dataset) == 0:\n",
        "    raise ValueError(\"The training dataset is empty. Please ensure frames are correctly extracted and organized.\")\n",
        "if len(test_dataset) == 0:\n",
        "    raise ValueError(\"The testing dataset is empty. Please ensure frames are correctly extracted and organized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhyeills2Epf"
      },
      "source": [
        "### Section 1-5: Create Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gDbQv4wzY-E"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders for training and testing\n",
        "trainloader = None\n",
        "\n",
        "testloader = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSnqIePW3dIg"
      },
      "source": [
        "## Section 2: Network Desing and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpTakViD2SeJ"
      },
      "source": [
        "### Section 2-1: Designing the Video Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kN0gXcg7rnHr"
      },
      "outputs": [],
      "source": [
        "class VideoClassificationModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VideoClassificationModel, self).__init__()\n",
        "\n",
        "        # Define a simple CNN model to process each frame\n",
        "        self.frame_cnn = nn.Sequential(\n",
        "            # Add a Conv2d layer with 3 input channels, 16 output channels,\n",
        "            #       kernel size of 3, stride of 1, and padding of 1\n",
        "\n",
        "            # Add a ReLU activation function\n",
        "\n",
        "            # Add a MaxPool2d layer with kernel size of 2 and stride of 2\n",
        "\n",
        "            # Add a Conv2d layer with 16 input channels, 32 output channels,\n",
        "            #       kernel size of 3, stride of 1, and padding of 1\n",
        "\n",
        "            # Add another ReLU activation function\n",
        "\n",
        "            # Add another MaxPool2d layer with kernel size of 2 and stride of 2\n",
        "\n",
        "            # Add a Conv2d layer with 32 input channels, 64 output channels,\n",
        "            #       kernel size of 3, stride of 1, and padding of 1\n",
        "\n",
        "            # Add a ReLU activation function\n",
        "\n",
        "            # Add a final MaxPool2d layer with kernel size of 2 and stride of 2\n",
        "        )\n",
        "\n",
        "        # MLP for aggregation after passing through CNN\n",
        "        # Adjust the input size based on the CNN output and number of frames\n",
        "        self.mlp = nn.Sequential(\n",
        "            # Add a Linear layer that flattens all frame features\n",
        "            #       (Input size should be 64 * 14 * 14 * 20) and outputs 512 features\n",
        "\n",
        "            # Add a ReLU activation function\n",
        "\n",
        "            # Add a Dropout layer with a probability of 0.5\n",
        "\n",
        "            # Add a final Linear layer that maps 512 features to the number of classes\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, num_frames, c, h, w = x.size()\n",
        "\n",
        "        # Initialize a list to hold features\n",
        "        frame_features = []\n",
        "\n",
        "        #### Your Code Here!\n",
        "        pass\n",
        "        ###\n",
        "\n",
        "        # Concatenate all frame features along the channel dimension\n",
        "        # Resulting shape: (batch_size, 64 * 20, 14, 14)\n",
        "        None\n",
        "\n",
        "        # Flatten the features\n",
        "        None\n",
        "\n",
        "        # Pass through MLP\n",
        "        None\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6PmX7xYzpNK"
      },
      "source": [
        "### Section 2-3: Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kiyT0pI-rpkc"
      },
      "outputs": [],
      "source": [
        "None\n",
        "None\n",
        "None\n",
        "\n",
        "# Optional: Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHoMbbP6tNEk"
      },
      "source": [
        "### Section 2-4: Train the network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixws1xdzmXw2"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "num_epochs = 10\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "test_accuracy_list = []\n",
        "\n",
        "for None:\n",
        "    #### Your Code Here!\n",
        "        pass\n",
        "    ###\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for None:\n",
        "\n",
        "        #### Your Code Here!\n",
        "        pass\n",
        "        ###\n",
        "\n",
        "        # Forward pass\n",
        "\n",
        "        #### Your Code Here!\n",
        "        pass\n",
        "        ###\n",
        "\n",
        "        # Backward pass\n",
        "\n",
        "        #### Your Code Here!\n",
        "        pass\n",
        "        ###\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "\n",
        "        #### Your Code Here!\n",
        "        pass\n",
        "        ###\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader)\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    train_accuracy_list.append(epoch_accuracy)\n",
        "\n",
        "    # Evaluate on test set\n",
        "\n",
        "    #### Your Code Here!\n",
        "        pass\n",
        "    ###\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for None:\n",
        "            #### Your Code Here!\n",
        "            pass\n",
        "            ###\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct_test / total_test\n",
        "    test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, \"\n",
        "          f\"Train Accuracy: {epoch_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGiU9_3wtO_E"
      },
      "source": [
        "### Section 2-5: Plot Loss and Accuracy Curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5Y7YAeTryoj"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(train_loss, train_acc, test_acc):\n",
        "    \"\"\"\n",
        "    Plots training loss, training accuracy, and test accuracy over epochs.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_loss, 'b-', marker='o', label='Training Loss')\n",
        "    plt.title('Training Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_acc, 'g-', marker='o', label='Training Accuracy')\n",
        "    plt.plot(epochs, test_acc, 'r-', marker='x', label='Test Accuracy')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training loss and accuracy curves\n",
        "plot_metrics(train_loss_list, train_accuracy_list, test_accuracy_list)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
